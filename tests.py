"""
ProjectFlow æ¸¬è©¦å¥—ä»¶

ç°¡å–®çš„æ¸¬è©¦æ¡†æ¶ï¼Œç”¨æ–¼é©—è­‰æ ¸å¿ƒåŠŸèƒ½
"""

import sys
import os
from pathlib import Path

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„åŠ å…¥è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

import unittest
from unittest.mock import Mock, patch
import json

# å°å…¥è¦æ¸¬è©¦çš„æ¨¡çµ„
from utils import (
    extract_first_json_list,
    safe_json_parse,
    count_tokens,
    TokenStats,
    validate_state,
    merge_states,
    truncate_text,
    clean_whitespace,
    clean_llm_response
)


class TestJSONParsing(unittest.TestCase):
    """æ¸¬è©¦ JSON è§£æåŠŸèƒ½"""
    
    def test_extract_simple_json_list(self):
        """æ¸¬è©¦è§£æç°¡å–®çš„ JSON list"""
        text = '[{"key": "value"}]'
        result = extract_first_json_list(text)
        self.assertEqual(result, [{"key": "value"}])
    
    def test_extract_json_with_text(self):
        """æ¸¬è©¦å¾åŒ…å«æ–‡å­—çš„å…§å®¹ä¸­æå– JSON"""
        text = 'é€™æ˜¯ä¸€äº›æ–‡å­— [{"key": "value"}] æ›´å¤šæ–‡å­—'
        result = extract_first_json_list(text)
        self.assertEqual(result, [{"key": "value"}])
    
    def test_extract_invalid_json(self):
        """æ¸¬è©¦è™•ç†ç„¡æ•ˆçš„ JSON"""
        text = 'é€™ä¸æ˜¯ JSON'
        result = extract_first_json_list(text)
        self.assertEqual(result, [])
    
    def test_safe_json_parse_valid(self):
        """æ¸¬è©¦å®‰å…¨è§£ææœ‰æ•ˆçš„ JSON"""
        text = '{"key": "value"}'
        result = safe_json_parse(text)
        self.assertEqual(result, {"key": "value"})
    
    def test_safe_json_parse_invalid(self):
        """æ¸¬è©¦å®‰å…¨è§£æç„¡æ•ˆçš„ JSON è¿”å›é è¨­å€¼"""
        text = 'invalid json'
        result = safe_json_parse(text, default={})
        self.assertEqual(result, {})


class TestTokenCounting(unittest.TestCase):
    """æ¸¬è©¦ Token è¨ˆæ•¸åŠŸèƒ½"""
    
    def test_count_tokens_basic(self):
        """æ¸¬è©¦åŸºæœ¬çš„ token è¨ˆæ•¸"""
        text = "Hello world"
        result = count_tokens(text)
        self.assertGreater(result, 0)
    
    def test_token_stats_initialization(self):
        """æ¸¬è©¦ TokenStats åˆå§‹åŒ–"""
        stats = TokenStats()
        self.assertEqual(stats.get_total(), 0)
    
    def test_token_stats_add_input(self):
        """æ¸¬è©¦æ·»åŠ è¼¸å…¥ token"""
        stats = TokenStats()
        stats.add_input("summary_agent", 100)
        self.assertEqual(stats.get_total_input(), 100)
    
    def test_token_stats_add_output(self):
        """æ¸¬è©¦æ·»åŠ è¼¸å‡º token"""
        stats = TokenStats()
        stats.add_output("score_agent", 50)
        self.assertEqual(stats.get_total_output(), 50)
    
    def test_token_stats_total(self):
        """æ¸¬è©¦ç¸½è¨ˆ token"""
        stats = TokenStats()
        stats.add_input("summary_agent", 100)
        stats.add_output("score_agent", 50)
        self.assertEqual(stats.get_total(), 150)
    
    def test_token_stats_reset(self):
        """æ¸¬è©¦é‡è¨­çµ±è¨ˆ"""
        stats = TokenStats()
        stats.add_input("summary_agent", 100)
        stats.reset()
        self.assertEqual(stats.get_total(), 0)


class TestStateManagement(unittest.TestCase):
    """æ¸¬è©¦ç‹€æ…‹ç®¡ç†åŠŸèƒ½"""
    
    def test_validate_state_valid(self):
        """æ¸¬è©¦é©—è­‰æœ‰æ•ˆçš„ç‹€æ…‹"""
        state = {
            "messages": [],
            "project_content": "",
            "session_id": "test"
        }
        required = ["messages", "project_content", "session_id"]
        self.assertTrue(validate_state(state, required))
    
    def test_validate_state_invalid(self):
        """æ¸¬è©¦é©—è­‰ç„¡æ•ˆçš„ç‹€æ…‹"""
        state = {
            "messages": []
        }
        required = ["messages", "project_content", "session_id"]
        self.assertFalse(validate_state(state, required))
    
    def test_merge_states(self):
        """æ¸¬è©¦åˆä½µç‹€æ…‹"""
        base = {"a": 1, "b": 2}
        update = {"b": 3, "c": 4}
        result = merge_states(base, update)
        expected = {"a": 1, "b": 3, "c": 4}
        self.assertEqual(result, expected)


class TestTextProcessing(unittest.TestCase):
    """æ¸¬è©¦æ–‡å­—è™•ç†åŠŸèƒ½"""
    
    def test_truncate_text_short(self):
        """æ¸¬è©¦æˆªæ–·çŸ­æ–‡å­—ï¼ˆä¸æ‡‰æˆªæ–·ï¼‰"""
        text = "çŸ­æ–‡å­—"
        result = truncate_text(text, max_length=10)
        self.assertEqual(result, "çŸ­æ–‡å­—")
    
    def test_truncate_text_long(self):
        """æ¸¬è©¦æˆªæ–·é•·æ–‡å­—"""
        text = "é€™æ˜¯ä¸€æ®µå¾ˆé•·çš„æ–‡å­—" * 10
        result = truncate_text(text, max_length=20)
        self.assertEqual(len(result), 20)
        self.assertTrue(result.endswith("..."))
    
    def test_clean_whitespace(self):
        """æ¸¬è©¦æ¸…ç†ç©ºç™½å­—å…ƒ"""
        text = """
        ç¬¬ä¸€è¡Œ  
        
        ç¬¬äºŒè¡Œ
        
        ç¬¬ä¸‰è¡Œ  
        """
        result = clean_whitespace(text)
        expected = "ç¬¬ä¸€è¡Œ\nç¬¬äºŒè¡Œ\nç¬¬ä¸‰è¡Œ"
        self.assertEqual(result, expected)
    
    def test_clean_llm_response_with_markers(self):
        """æ¸¬è©¦æ¸…ç†åŒ…å«å…§éƒ¨æ¨ç†æ¨™è¨˜çš„ LLM å›æ‡‰"""
        text = """analysisWe need to think about this...
        Let's analyze the situation.
        assistantfinalé€™æ˜¯å¯¦éš›çš„å›æ‡‰å…§å®¹"""
        result = clean_llm_response(text)
        # æ‡‰è©²ç§»é™¤ analysis å’Œ assistantfinal ä¹‹é–“çš„å…§å®¹
        self.assertNotIn("analysis", result.lower())
        self.assertNotIn("assistantfinal", result.lower())
        self.assertIn("é€™æ˜¯å¯¦éš›çš„å›æ‡‰å…§å®¹", result)
    
    def test_clean_llm_response_normal(self):
        """æ¸¬è©¦æ¸…ç†æ­£å¸¸çš„ LLM å›æ‡‰ï¼ˆç„¡æ¨™è¨˜ï¼‰"""
        text = "é€™æ˜¯æ­£å¸¸çš„å›æ‡‰ï¼Œæ²’æœ‰ä»»ä½•æ¨™è¨˜"
        result = clean_llm_response(text)
        self.assertEqual(result, text)
    
    def test_clean_llm_response_issue_example(self):
        """æ¸¬è©¦æ¸…ç†å¯¦éš›å•é¡Œæ¡ˆä¾‹"""
        text = """analysisWe need to generate a response as BuddyG...
Ok.assistantfinalç¾åœ¨æˆ‘å€‘æ­£è™•æ–¼ã€Œå•é¡Œæ¢ç´¢ã€çš„éšæ®µï¼Œä¸€èµ·æ‰¾å‡ºä½ æœ€é—œå¿ƒçš„æ°¸çºŒè­°é¡Œå§ï¼

å—¨ï¼Œä½ å¥½ ğŸ‘‹"""
        result = clean_llm_response(text)
        # ç¢ºä¿å…§éƒ¨æ¨ç†è¢«ç§»é™¤
        self.assertNotIn("analysisWe", result)
        self.assertNotIn("BuddyG", result)
        # ç¢ºä¿å¯¦éš›å…§å®¹ä¿ç•™
        self.assertIn("ç¾åœ¨æˆ‘å€‘æ­£è™•æ–¼ã€Œå•é¡Œæ¢ç´¢ã€çš„éšæ®µ", result)
        self.assertIn("å—¨ï¼Œä½ å¥½ ğŸ‘‹", result)
    
    def test_clean_llm_response_preserve_legitimate_analysis(self):
        """æ¸¬è©¦ä¿ç•™æ­£å¸¸æ–‡å­—ä¸­çš„ analysis è©å½™"""
        text = "æˆ‘å€‘éœ€è¦åšæ•¸æ“šåˆ†æï¼ˆanalysisï¼‰ä¾†è§£æ±ºé€™å€‹å•é¡Œ"
        result = clean_llm_response(text)
        # ç¢ºä¿æ­£å¸¸å…§å®¹ä¸­çš„ analysis ä¸è¢«ç§»é™¤
        self.assertIn("analysis", result.lower())
        self.assertEqual(result, text)


class TestConfiguration(unittest.TestCase):
    """æ¸¬è©¦é…ç½®ç®¡ç†"""
    
    def test_import_config(self):
        """æ¸¬è©¦å°å…¥é…ç½®æ¨¡çµ„"""
        try:
            import config
            self.assertTrue(hasattr(config, 'LLMConfig'))
            self.assertTrue(hasattr(config, 'LogConfig'))
            self.assertTrue(hasattr(config, 'APIConfig'))
        except ImportError as e:
            self.fail(f"ç„¡æ³•å°å…¥ config æ¨¡çµ„: {e}")
    
    @patch.dict(os.environ, {
        'AZURE_OPENAI_ENDPOINT': 'http://test.com',
        'AZURE_OPENAI_API_KEY': 'test-key'
    })
    def test_llm_config_use_openai(self):
        """æ¸¬è©¦ LLM é…ç½®åˆ¤æ–·ä½¿ç”¨ OpenAI"""
        # å‹•æ…‹å»ºç«‹é…ç½®é¡åˆ¥ä»¥æ¸¬è©¦ç’°å¢ƒè®Šæ•¸
        class TestLLMConfig:
            AZURE_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
            AZURE_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
            
            @classmethod
            def use_openai(cls) -> bool:
                return bool(cls.AZURE_ENDPOINT and cls.AZURE_API_KEY)
        
        self.assertTrue(TestLLMConfig.use_openai())


class TestPrompts(unittest.TestCase):
    """æ¸¬è©¦ Prompt æ¨¡æ¿"""
    
    def test_import_prompts(self):
        """æ¸¬è©¦å°å…¥ prompts æ¨¡çµ„"""
        try:
            import prompts
            self.assertTrue(hasattr(prompts, 'SUMMARY_AGENT_PROMPT'))
            self.assertTrue(hasattr(prompts, 'SCORE_AGENT_PROMPT'))
            self.assertTrue(hasattr(prompts, 'DECISION_AGENT_PROMPT'))
            self.assertTrue(hasattr(prompts, 'RESPONSE_AGENT_PROMPT'))
        except ImportError as e:
            self.fail(f"ç„¡æ³•å°å…¥ prompts æ¨¡çµ„: {e}")
    
    def test_prompt_not_empty(self):
        """æ¸¬è©¦ Prompt ä¸ç‚ºç©º"""
        import prompts
        self.assertGreater(len(prompts.SUMMARY_AGENT_PROMPT), 0)
        self.assertGreater(len(prompts.SCORE_AGENT_PROMPT), 0)
        self.assertGreater(len(prompts.DECISION_AGENT_PROMPT), 0)
        self.assertGreater(len(prompts.RESPONSE_AGENT_PROMPT), 0)


def run_tests(verbosity=2):
    """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
    # å»ºç«‹æ¸¬è©¦å¥—ä»¶
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # æ·»åŠ æ‰€æœ‰æ¸¬è©¦
    suite.addTests(loader.loadTestsFromTestCase(TestJSONParsing))
    suite.addTests(loader.loadTestsFromTestCase(TestTokenCounting))
    suite.addTests(loader.loadTestsFromTestCase(TestStateManagement))
    suite.addTests(loader.loadTestsFromTestCase(TestTextProcessing))
    suite.addTests(loader.loadTestsFromTestCase(TestConfiguration))
    suite.addTests(loader.loadTestsFromTestCase(TestPrompts))
    
    # åŸ·è¡Œæ¸¬è©¦
    runner = unittest.TextTestRunner(verbosity=verbosity)
    result = runner.run(suite)
    
    # è¿”å›æ¸¬è©¦çµæœ
    return result.wasSuccessful()


if __name__ == "__main__":
    # åŸ·è¡Œæ¸¬è©¦ä¸¦æ ¹æ“šçµæœè¨­å®šé€€å‡ºç¢¼
    success = run_tests()
    sys.exit(0 if success else 1)
